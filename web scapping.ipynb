{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page Text:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "What is Web Scraping and What is it Used For? | ParseHub\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "|\n",
      "Blog\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Download\n",
      "Pricing\n",
      "Free Courses\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "              parsehub.com\n",
      "          \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "14 April 2023\n",
      "/ Web Scraping\n",
      "\n",
      "What is Web Scraping and What is it Used For?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Web scraping is one of the most efficient and useful ways to extract data from a website, especially in 2023!Some websites can contain a very large amount of invaluable data.Stock prices, product details, sports stats, company contacts, you name it.If you wanted to access this information, you’d either have to use whatever format the website uses or copy-paste the information manually into a new document. Here’s where web scraping can help.What is Web Scraping?Web scraping refers to the extraction of data from a website. This information is collected and then exported into a format that is more useful for the user. Be it a spreadsheet or an API.Although web scraping can be done manually, in most cases, automated tools are preferred when scraping web data as they can be less costly and work at a faster rate.But in most cases, web scraping is not a simple task. Websites come in many shapes and forms, as a result, web scrapers vary in functionality and features.Please note that you may encounter captchas when attempting to scrape some websites, so we suggest reading several guides on how to avoid & bypass captchas before scraping a website:How to avoid and bypass captchasSolving Captcha (for all Paid plans)If you want to find the best web scraper for your project, make sure to read on.Is web scraping legal?In short, the action of web scraping isn't illegal. However, some rules need to be followed. Web scraping becomes illegal when non publicly available data becomes extracted.This comes as no surprise given the growth of web scraping and many recent legal cases related to web scraping.If you want to learn more about the legality of web scraping, you can continue reading here: Is web scraping legal? How do Web Scrapers Work?So, how do web scrapers work? Automated web scrapers work in a rather simple but also complex way. After all, websites are built for humans to understand, not machines.First, the web scraper will be given one or more URLs to load before scraping. The scraper then loads the entire HTML code for the page in question. More advanced scrapers will render the entire website, including CSS and Javascript elements.Then the scraper will either extract all the data on the page or specific data selected by the user before the project is run.Ideally, the user will go through the process of selecting the specific data they want from the page. For example, you might want to scrape an Amazon product page for prices and models but are not necessarily interested in product reviews.Lastly, the web scraper will output all the data that has been collected into a format that is more useful to the user.Most web scrapers will output data to a CSV or Excel spreadsheet, while more advanced scrapers will support other formats such as JSON which can be used for an API.What Kind of Web Scrapers are There?Web scrapers can drastically differ from each other on a case-by-case basis.For simplicity’s sake, we will break down some of these aspects into 4 categories. Of course, there are more intricacies at play when comparing web scrapers.self-built or pre-builtbrowser extension vs softwareUser interfaceCloud vs LocalSelf-built or Pre-builtJust like how anyone can build a website, anyone can build their own web scraper.However, the tools available to build your own web scraper still require some advanced programming knowledge. The scope of this knowledge also increases with the number of features you’d like your scraper to have.On the other hand, there are numerous pre-built web scrapers that you can download and run right away. Some of these will also have advanced options added such as scrape scheduling, JSON and Google Sheets exports and more.Browser extension vs SoftwareIn general terms, web scrapers come in two forms: browser extensions or computer software.Browser extensions are app-like programs that can be added to your browsers such as Google Chrome or Firefox. Some popular browser extensions include themes, ad blockers, messaging extensions and more.Web scraping extensions have the benefit of being simpler to run and being integrated right into your browser.However, these extensions are usually limited by living in your browser. Meaning that any advanced features that would have to occur outside of the browser would be impossible to implement. For example, IP Rotations would not be possible in this kind of extension.On the other hand, you will have actual web scraping software that can be downloaded and installed on your computer. While these are a bit less convenient than browser extensions, they make up for it in advanced features that are not limited by what your browser can and cannot do.User InterfaceThe user interface between web scrapers can vary quite extremely.For example, some web scraping tools will run with a minimal UI and a command line. Some users might find this unintuitive or confusing.On the other hand, some web scrapers will have a full-fledged UI where the website is fully rendered for the user to just click on the data they want to scrape. These web scrapers are usually easier to work with for most people with limited technical knowledge.Some scrapers will go as far as integrating help tips and suggestions through their UI to make sure the user understands each feature that the software offers.Cloud vs LocalFrom where does your web scraper actually do its job?Local web scrapers will run on your computer using its resources and internet connection. This means that if your web scraper has a high usage of CPU or RAM, your computer might become quite slow while your scrape runs. With long scraping tasks, this could put your computer out of commission for hours.Additionally, if your scraper is set to run on a large number of URLs (such as product pages), it can have an impact on your ISP’s data caps.Cloud-based web scrapers run on an off-site server which is usually provided by the company that developed the scraper itself. This means that your computer’s resources are freed up while your scraper runs and gathers data. You can then work on other tasks and be notified later once your scrape is ready to be exported.This also allows for very easy integration of advanced features such as IP rotation, which can prevent your scraper from getting blocked from major websites due to their scraping activity.What are Web Scrapers Used For?By this point, you can probably think of several different ways in which web scrapers can be used. We’ve put some of the most common ones below (plus a few unique ones).Real Estate Listing ScrapingMany real estate agents use web scraping to populate their database of available properties for sale or for rent.For example, a real estate agency will scrape MLS listings to build an API that directly populates this information onto their website. This way, they get to act as the agent for the property when someone finds this listing on their site.Most listings that you will find on a Real Estate website are automatically generated by an API.Industry Statistics and InsightsMany companies use web scraping to build massive databases and draw industry-specific insights from these. These companies can then sell access to these insights to companies in said industries.For example, a company might scrape and analyze tons of data about oil prices, exports and imports in order to sell their insights to oil companies across the world.Comparison Shopping SitesSome several websites and applications can help you to easily compare pricing between several retailers for the same product.One way that these websites work is by using web scrapers to scrape product data and pricing from each retailer daily. This way, they can provide their users with the comparison data they need.Lead GenerationOne incredibly popular use of web scraping is lead generation. This use is so popular in fact, that we have written an entire guide on using web scraping for lead generation.In short, web scraping is used by many companies to collect contact information about potential customers or clients. This is incredibly common in the business-to-business space, where potential customers will post their business information publicly online.Check out our guides of how you can use web scraping for your business:Scraping stock prices into an app APIScraping data from YellowPages to generate leadsScraping data from a store locator to create a list of business locationsScraping product data from sites like Amazon or eBay for competitor analysisScraping sports stats for betting or fantasy leaguesScraping site data before a website migrationScraping product details for comparison shoppingScraping financial data for market research and insightsThe list of things you can do with web scraping is almost endless. After all, it is all about what you can do with the data you’ve collected and how valuable you can make it.Read our Beginner's guide to web scraping to start learning how to scrape any website!The Best Web ScraperSo, now that you know the basics of web scraping, you’re probably wondering what is the best web scraper for you?The obvious answer is that it depends.The more you know about your scraping needs, the better of an idea you will have about what’s the best web scraper for you. However, that did not stop us from writing our guide on what makes the Best Web Scraper.Of course, we would always recommend ParseHub. Not only can it be downloaded for FREE but it comes with an incredibly powerful suite of features which we reviewed in this article. Including a friendly UI, cloud-based scrapping, awesome customer support and more.Learn more about ParseHub and download it for free.Want to become an expert on Web Scraping for Free? Take our free web scraping courses and become Certified in Web Scraping today!If you are interested in getting the data you want right away without having to learn, we offer web scraping services. Our team of web scraping experts will extract any data from the most complex websites. Book a free call today!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Martin Perez\n",
      "Martin is the Digital Marketing Specialist at ParseHub. A lover of all things related to tech, culture, and the internet. \n",
      "\n",
      "\n",
      "\n",
      "Read More\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "— Web Scraping Blog (Tips, Guides + Tutorials) | ParseHub —\n",
      "Web Scraping\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "How to Scrape a Website that Requires a Login in 2023.\n",
      "How to Scrape and Download All PDF Files on a Website\n",
      "[2023 Tutorial] How to Scrape Amazon Product Data: Names, Pricing, ASIN, etc.\n",
      "\n",
      "\n",
      "\n",
      "See all 63 posts →\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Rising Cost of Groceries in Canada: Web Scraping Reveals Inflation\n",
      "\n",
      "\n",
      "Shopping for groceries in Canada is becoming more and more costly, with worrisome inflation patterns. The outcry from shoppers can be heard across the country as everyday items become increasingly expensive; Google Trends\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                        Farzad Vafaei\n",
      "                    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "4 min read\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Web Scraping\n",
      "How to Scrape and Download All PDF Files on a Website\n",
      "\n",
      "\n",
      "PDF files are incredibly common on the internet.\n",
      "\n",
      "There might be scenarios where you might have to download a long list of PDF files from a website.\n",
      "\n",
      "If the number of files is\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                        Martin Perez\n",
      "                    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "3 min read\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Web Scraping Blog (Tips, Guides + Tutorials) | ParseHub\n",
      "\n",
      "\n",
      "—\n",
      "What is Web Scraping and What is it Used For?\n",
      "\n",
      "Share this \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Web Scraping Blog (Tips, Guides + Tutorials) | ParseHub © 2024\n",
      "\n",
      "Latest Posts\n",
      "Facebook\n",
      "Twitter\n",
      "Ghost\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Links:\n",
      "/blog\n",
      "/blog\n",
      "https://www.parsehub.com/quickstart\n",
      "https://www.parsehub.com/pricing\n",
      "https://academy.parsehub.com/\n",
      "https://www.facebook.com/ParseHubApp/\n",
      "https://twitter.com/parsehub\n",
      "https://feedly.com/i/subscription/feed/https://www.parsehub.com/blog/rss/\n",
      "/\n",
      "/blog/tag/web-scraping/\n",
      "https://parsehub.com/?ref=parsehub.com\n",
      "https://www.upwork.com/search/profiles/?nbs=1&q=web+scraping&ref=parsehub.com\n",
      "https://www.expertmarket.co.uk/web-design/different-types-of-websites?ref=parsehub.com\n",
      "https://proxyway.com/guides/how-to-bypass-captcha?ref=parsehub.com\n",
      "https://help.parsehub.com/hc/en-us/articles/115004504048-Solving-Captcha-for-all-Paid-plans-?ref=parsehub.com\n",
      "https://www.parsehub.com/blog/web-scraping-legal/\n",
      "https://www.parsehub.com/blog/how-web-scraping-works/\n",
      "https://parsehub.com/?ref=parsehub.com\n",
      "https://www.parsehub.com/?ref=parsehub.com\n",
      "https://www.parsehub.com/blog/web-scraping-excel-sheet/\n",
      "https://www.datacamp.com/community/tutorials/making-web-crawlers-scrapy-python?ref=parsehub.com\n",
      "www.parsehub.com/blog/scrape-data-json/\n",
      "www.parsehub.com/blog/scrape-web-content-into-google-sheets/\n",
      "https://chrome.google.com/webstore/category/extensions?ref=parsehub.com\n",
      "https://www.parsehub.com/blog/best-tools-web-scraping/\n",
      "https://www.parsehub.com/blog/a-complete-guide-on-offering-web-scraping-services/\n",
      "https://www.parsehub.com/blog/scrape-yahoo-finance/\n",
      "https://www.parsehub.com/blog/find-business-leads-and-contact-info-from-yellowpages/\n",
      "https://www.parsehub.com/blog/how-to-get-the-locations-of-retail-stores-with-web-scraping/\n",
      "https://www.parsehub.com/blog/scrape-competitor-prices-from-ebay/\n",
      "https://www.parsehub.com/blog/power-your-sports-stats-with-web-scraping/\n",
      "https://www.parsehub.com/blog/using-parsehub-to-compare-sneaker-prices/\n",
      "https://www.parsehub.com/blog/scrape-financial-statements/\n",
      "https://www.parsehub.com/blog/beginners-guide-to-web-scraping/\n",
      "https://parsehub.com/blog/web-scraping-basics/?ref=parsehub.com\n",
      "https://www.parsehub.com/blog/best-web-scraper/\n",
      "https://parsehub.com/?ref=parsehub.com\n",
      "https://parsehub.com/quickstart?ref=parsehub.com\n",
      "https://parsehub.com/features?ref=parsehub.com\n",
      "https://academy.parsehub.com/?ref=parsehub.com\n",
      "https://plus.parsehub.com/?ref=parsehub.com\n",
      "/blog/author/martin-perez/\n",
      "/blog/author/martin-perez/\n",
      "/blog/tag/web-scraping/\n",
      "/blog/web-scrape-login/\n",
      "/blog/scrape-download-pdf-files/\n",
      "/blog/scrape-amazon-product-data/\n",
      "/blog/tag/web-scraping/\n",
      "/blog/rising-cost-groceries-canada-web-scraping-inflation/\n",
      "/blog/rising-cost-groceries-canada-web-scraping-inflation/\n",
      "/blog/author/farzad/\n",
      "/blog/scrape-download-pdf-files/\n",
      "/blog/scrape-download-pdf-files/\n",
      "/blog/author/martin-perez/\n",
      "https://www.parsehub.com/blog\n",
      "https://twitter.com/share?text=What%20is%20Web%20Scraping%20and%20What%20is%20it%20Used%20For%3F&url=https://www.parsehub.com/blog/what-is-web-scraping/\n",
      "https://www.facebook.com/sharer/sharer.php?u=https://www.parsehub.com/blog/what-is-web-scraping/\n",
      "https://www.parsehub.com/blog\n",
      "https://www.parsehub.com/blog\n",
      "https://www.facebook.com/ParseHubApp/\n",
      "https://twitter.com/parsehub\n",
      "https://ghost.org\n",
      "\n",
      "Images:\n",
      "/blog/assets/images/parsehub_logo3.svg?v=22c6426566\n",
      "/blog/assets/images/parsehub_logo_icon.svg?v=22c6426566\n",
      "/blog/assets/images/exit.svg?v=22c6426566\n",
      "/blog/content/images/size/w2000/2021/06/What-is-web-scraping-1.jpeg\n",
      "https://www.parsehub.com/blog/content/images/2021/06/what-is-web-sraping-parsehub.jpeg\n",
      "https://www.parsehub.com/blog/content/images/2021/06/web-to-google-sheet.jpeg\n",
      "https://www.parsehub.com/blog/content/images/2021/06/types-of-web-scrapers.jpeg\n",
      "https://www.parsehub.com/blog/content/images/2021/06/what-are-scrapers-used-for.jpeg\n",
      "/blog/content/images/size/w100/2019/07/mp-resized.jpg\n",
      "/blog/content/images/size/w600/2023/04/Rising-Cost-of-Groceries-in-Canada-Web-Scraping-Reveals-Inflation--1-.jpg\n",
      "/blog/content/images/size/w100/2022/06/profilepic.jpg\n",
      "/blog/content/images/size/w600/2020/04/scrape-download-pdf-files.jpg\n",
      "/blog/content/images/size/w100/2019/07/mp-resized.jpg\n",
      "/blog/content/images/size/w30/2019/08/parsehub_logo2.png\n",
      "Failed to retrieve the web page. Status code:200\n"
     ]
    }
   ],
   "source": [
    "import requests # type: ignore\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#URL of the web page to scrape\n",
    "url=\"https://www.parsehub.com/blog/what-is-web-scraping/\" #Replace with the URL of the web page you want to scrape\n",
    "\n",
    "#Send a GET request was successful \n",
    "response=requests.get(url)\n",
    "\n",
    "#Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    #Parse the HTML content of the page\n",
    "    soup=BeautifulSoup(response.text,'html.parser')\n",
    "    \n",
    "    #Extract all the text from the page\n",
    "    page_text= soup.get_text()\n",
    "    \n",
    "    #Extract all the links from the page\n",
    "    links=[a['href'] for a in soup.find_all('a', href=True)]\n",
    "    \n",
    "    #Extract all the images from the page\n",
    "    images=[img['src'] for img in soup.find_all('img',src=True)]\n",
    "\n",
    "    #Print the extracted data \n",
    "    print(\"Page Text:\")\n",
    "    print(page_text)\n",
    "\n",
    "    print('\\nLinks:')\n",
    "    for link in links:\n",
    "        print(link)\n",
    "    \n",
    "    print(\"\\nImages:\")\n",
    "    for image in images:\n",
    "        print(image)\n",
    "\n",
    "    else:\n",
    "        print(f'Failed to retrieve the web page. Status code:{response.status_code}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
